{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from significance_of_mean_cuda import significance_of_mean_cuda\n",
    "from utils import significance_of_mean, getNumerator, pValue\n",
    "import numpy as np\n",
    "import time\n",
    "import multiprocessing\n",
    "import concurrent.futures as cf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['text.usetex'] = False  # not really needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = [50,100, 150, 200, 250]\n",
    "s =  [10, 50, 100, 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The calculations are parallelized over the samples on five cores in total. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_value_calc(args):\n",
    "    a,b, bins = args\n",
    "    p=significance_of_mean(a,b, bins)[0]\n",
    "    return p\n",
    "\n",
    "def calibration_series_generator(A,B, S):\n",
    "    num_tests = A.shape[0]\n",
    "    for i in range(num_tests):\n",
    "        a_sample = A[i].tolist()\n",
    "        b_sample = B[i].tolist()\n",
    "        yield ([a_sample,b_sample, S])\n",
    "\n",
    "def calibration_test(A,B,bins):\n",
    "    with cf.ProcessPoolExecutor(max_workers=multiprocessing.cpu_count()-3) as pool:\n",
    "        p_list = list(pool.map(p_value_calc, calibration_series_generator(A,B, bins)))\n",
    "    return p_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU:  0.019036531448364258\n",
      "CPU:  0.18491458892822266\n",
      "True\n",
      "GPU:  0.021863698959350586\n",
      "CPU:  1.814922571182251\n",
      "True\n",
      "GPU:  0.02924346923828125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ac48811344e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalibration_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mt_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-73edec74c42f>\u001b[0m in \u001b[0;36mcalibration_test\u001b[0;34m(A, B, bins)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalibration_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcessPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mp_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_value_calc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalibration_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/process.py\u001b[0m in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0mcareful\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mto\u001b[0m \u001b[0mkeep\u001b[0m \u001b[0mreferences\u001b[0m \u001b[0mto\u001b[0m \u001b[0myielded\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \"\"\"\n\u001b[0;32m--> 476\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m         \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    584\u001b[0m                     \u001b[0;31m# Careful not to keep a reference to the popped future\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                         \u001b[0;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cpu = list()\n",
    "gpu = list()\n",
    "n = N[1]\n",
    "for bins in s:\n",
    "    np.random.seed(42)\n",
    "    A = np.asarray([np.random.normal(0, 1, n) for _ in range(num_examples)])\n",
    "    B = np.asarray([np.random.normal(0, 1, n) for _ in range(num_examples)])\n",
    "\n",
    "    start = time.time()\n",
    "    SGM = significance_of_mean_cuda(bins,dtype_v=np.uint16,dtype_A=np.float64)\n",
    "    SGM.run(A,B)\n",
    "    p = SGM.get_p_values()\n",
    "    end = time.time()\n",
    "    t_gpu = end - start\n",
    "    gpu.append(t_gpu)\n",
    "    print(\"GPU: \", t_gpu)\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    P = calibration_test(A,B,bins)\n",
    "    end = time.time()\n",
    "    t_cpu = end - start\n",
    "    cpu.append(t_cpu)\n",
    "    print(\"CPU1: \",t_cpu)\n",
    "    \n",
    "\n",
    "    \n",
    "    x = list(A[0])\n",
    "    y = list(B[0])\n",
    "    m = len(x)\n",
    "    n = len(y)\n",
    "    z = x + y;z.sort()\n",
    "    S = sum(z[m:])\n",
    "    dtype = np.uint16\n",
    "    \n",
    "    start = time.time()\n",
    "    N = getNumerator(m, n, S, list(z), np.float64)\n",
    "    end = time.time()\n",
    "    t_cpu = end - start\n",
    "    cpu.append(t_cpu)\n",
    "    print(\"CPU2: \",t_cpu)\n",
    "    \n",
    "    print(np.allclose(p,P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(s, cpu, 'r-', label='Not parallelized')\n",
    "plt.plot(s, gpu, 'g-', label='Parallelized')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel(r\"$n_{bins}$\")\n",
    "plt.ylabel(\"Time(s)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/normal_S\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = list()\n",
    "gpu = list()\n",
    "bins = s[2]\n",
    "for n in N:\n",
    "    np.random.seed(42)\n",
    "    A = np.asarray([np.random.normal(0, 1, n) for _ in range(num_examples)])\n",
    "    B = np.asarray([np.random.normal(0, 1, n) for _ in range(num_examples)])\n",
    "\n",
    "    start = time.time()\n",
    "    SGM = significance_of_mean_cuda(bins,dtype_v=np.uint16,dtype_A=np.float64)\n",
    "    PC = SGM.run(A,B)\n",
    "    end = time.time()\n",
    "    t_gpu = end - start\n",
    "    gpu.append(t_gpu)\n",
    "    print(\"GPU: \", t_gpu)\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    P = calibration_test(A,B,bins)\n",
    "    end = time.time()\n",
    "    t_cpu = end - start\n",
    "    cpu.append(t_cpu)\n",
    "    print(\"CPU: \",t_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(N, cpu, 'r-', label='Not parallelized')\n",
    "plt.plot(N, gpu, 'g-', label='Parallelized')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel(r\"$n$\")\n",
    "plt.ylabel(\"Time(s)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/normal_N\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 200\n",
    "n = N[1]\n",
    "bins = s[2]\n",
    "\n",
    "np.random.seed(42)\n",
    "A = np.asarray([np.random.normal(0, 1, n) for _ in range(num_examples)])\n",
    "B = np.asarray([np.random.normal(0, 1, n) for _ in range(num_examples)])\n",
    "\n",
    "SGM = significance_of_mean_cuda(bins,dtype_v=np.uint16,dtype_A=np.float64)\n",
    "PC = SGM.run(A,B)\n",
    "\n",
    "pDf = getdf(PC)\n",
    "my_scatter_plot(pDf,\"figures/normal_calibration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pDf = getdf(PC)\n",
    "my_scatter_plot(pDf,\"figures/normal_calibration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 300\n",
    "n = N[0]\n",
    "bins = s[3]\n",
    "\n",
    "np.random.seed(42)\n",
    "A = np.asarray([np.random.exponential(1, n) for _ in range(num_examples)])\n",
    "B = np.asarray([np.random.exponential(1, n) for _ in range(num_examples)])\n",
    "\n",
    "SGM = significance_of_mean_cuda(bins,dtype_v=np.uint16,dtype_A=np.float64)\n",
    "PC = SGM.run(A,B)\n",
    "\n",
    "pDf = getdf(PC)\n",
    "my_scatter_plot(pDf,\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = list()\n",
    "gpu = list()\n",
    "n = N[0]\n",
    "for bins in s:\n",
    "    start = time.time()\n",
    "    SGM = significance_of_mean_cuda(bins,dtype_v=np.uint16,dtype_A=np.float64)\n",
    "    PC = SGM.run(A,B)\n",
    "    end = time.time()\n",
    "    t_gpu = end - start\n",
    "    gpu.append(t_gpu)\n",
    "    print(\"GPU: \", t_gpu)\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    P = calibration_test(A,B,bins)\n",
    "    end = time.time()\n",
    "    t_cpu = end - start\n",
    "    cpu.append(t_cpu)\n",
    "    print(\"CPU: \",t_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdf(P):\n",
    "    P.sort()\n",
    "    p_arr = np.array(P)\n",
    "    offset = 1.0/float(num_examples)\n",
    "    ideal_arr = np.linspace(offset,1.0-offset,num_examples)\n",
    "    Pdf = pd.DataFrame({'Observed p-value':p_arr,'Theoretical p-value':ideal_arr})\n",
    "    return Pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_scatter_plot(df,save_name):\n",
    "    sns.set(style=\"white\")\n",
    "    sns.set_context(\"talk\")\n",
    "    low = min(df[\"Theoretical p-value\"])\n",
    "    hi = max(df[\"Theoretical p-value\"])\n",
    "    f, ax = plt.subplots(figsize=(7, 7))\n",
    "    ax.set(xscale=\"log\", yscale=\"log\")\n",
    "    g=sns.regplot(x='Theoretical p-value', y ='Observed p-value', data=df,  ax=ax, fit_reg=False, scatter_kws={\"s\": 5})\n",
    "    # sns.lmplot(x='Theoretical p-value', y ='Observed p-value', fit_reg=False, data = df, scatter_kws={\"marker\": \"D\",  \"s\": 10})\n",
    "    # sns.relplot(x='Theoretical p-value', y ='Observed p-value', data = df)\n",
    "    g.plot([low,hi], [low,hi], 'k-', linewidth=.5)\n",
    "    sns.despine()\n",
    "    f.tight_layout()\n",
    "    f.savefig(save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scatter_plot(Pdf,\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(P,PC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The parallelized version is faster and yields the same p-values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(107.3141598701477 / 14.397771835327148,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximately 7.5 faster than the non-parallelized version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of increasing sample sizes. Sample-sizes larger than 160 yields memory error on the non-parallelized version, so the experiment stops there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listsizes = [20,60,120,160]\n",
    "plain_shift = list()\n",
    "gpu_shift = list()\n",
    "bins = 200\n",
    "for size in listsizes:\n",
    "    np.random.seed(1)\n",
    "    A = np.asarray([np.random.beta(2.0,5.0,size) for _ in range(5)])\n",
    "    B = np.asarray([np.random.beta(2.0,5.0,size) for _ in range(5)])\n",
    "    start = time.time()\n",
    "    P = calibration_test(A,B)\n",
    "    end = time.time()\n",
    "    plain_shift.append(round(end - start,3))\n",
    "    print(\"Plain\")\n",
    "    print(round(end - start,3))\n",
    "    \n",
    "    start = time.time()\n",
    "    SGM = significance_of_mean_cuda(bins,dtype_v=np.uint32,dtype_A=np.float64)\n",
    "    PC = SGM.run(A,B)\n",
    "    end = time.time()\n",
    "    gpu_shift.append(round(end - start,3))\n",
    "    print(\"GPU\")\n",
    "    print(round(end - start,3))\n",
    "    \n",
    "    print(np.allclose(PC,P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(listsizes, plain_shift, 'r-', label='Non-parallelized')\n",
    "plt.plot(listsizes, gpu_shift, 'g-', label='GPU shift-method')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel(\"Sample size\")\n",
    "plt.ylabel(\"Time(s)\")\n",
    "plt.savefig(\"figures/comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (test)",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
