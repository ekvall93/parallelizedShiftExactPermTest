{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from significance_of_mean_cuda import significance_of_mean_cuda\n",
    "from utils import significance_of_mean, getdf, my_scatter_plot\n",
    "import numpy as np\n",
    "import time\n",
    "import multiprocessing\n",
    "import concurrent.futures as cf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import truncnorm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, ttest_rel, chisquare, ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['text.usetex'] = False  # not really needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samp_cont(seed, X_mean, size=30):\n",
    "    np.random.seed(seed)\n",
    "    X = np.random.normal(X_mean, 1, size)\n",
    "    Y = np.random.normal(0, 1, size)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abosolute diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff(val1, val2):\n",
    "    return np.array(val1) - np.array(val2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel_error(val1, val2):\n",
    "    return (np.array(val1) - np.array(val2)) / np.array(val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(seed,sample_size, p_dict, sample_func, x_mean=0,bins=None):\n",
    "    #Get samples\n",
    "    X, Y = sample_func(seed, x_mean, sample_size)\n",
    "    \n",
    "    #Ttest\n",
    "    p_dict[\"ttest\"].append(ttest_ind(X, Y)[1])\n",
    "    \n",
    "    #Exact test\n",
    "    SGM = significance_of_mean_cuda(bins, dtype_v=np.uint16,dtype_A=np.float64)\n",
    "    SGM.run(X.reshape(1,-1),Y.reshape(1,-1))\n",
    "    p_dict[\"exact\"].append(SGM.p_values[0])\n",
    "        \n",
    "    return p_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment func: $n_{bins}=[10,12,...,40]$, Number of $n_{samples}=70$, Set-size $|A|=|B|=100$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_for_dist(x_mean):\n",
    "    Bin = list()\n",
    "    Diff = list()\n",
    "    Diff_rel = list()\n",
    "    for nbins in range(10,42,2):\n",
    "        p_val = dict()\n",
    "        p_val[\"ttest\"], p_val[\"exact\"] = list(), list()\n",
    "        for s in range(70):\n",
    "            p_val = run_test(s, 100, p_val, get_samp_cont, x_mean, bins=nbins)\n",
    "        #Divide ttest with 2 since sklearn calculate 2-side p-value.\n",
    "        dif = get_diff(p_val[\"exact\"], np.asarray(p_val[\"ttest\"]) / 2 )\n",
    "        dif_rel = rel_error(p_val[\"exact\"], np.asarray(p_val[\"ttest\"]) / 2 )\n",
    "        Diff.append(dif)\n",
    "        Bin.append(nbins)\n",
    "        Diff_rel.append(dif_rel)\n",
    "    return Diff, Diff_rel, Bin\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run experiment with $\\mu=[0,0.2,\\ldots,1.8,2]$ and save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_s = 0.2\n",
    "all_experiment_dif, all_experiment_rel_dif, all_experiment_bins = list(), list(), list()\n",
    "for i, m in enumerate(np.arange(0, 2.2, step_s)):\n",
    "    Diff,Diff_rel, Bin = test_for_dist(m)\n",
    "    all_experiment_dif.append(Diff)\n",
    "    all_experiment_rel_dif.append(Diff_rel)\n",
    "    all_experiment_bins.append(Bin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxPlot(error, Bin, error_type=\"abs\",path=None):\n",
    "    for d, b in zip(error, Bin):\n",
    "        my_dict[str(b)] = d\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.boxplot(my_dict.values())\n",
    "    ax.set_xticklabels(my_dict.keys())\n",
    "    \n",
    "    if error_type==\"abs\":\n",
    "        plt.ylabel(r\"$p_{exact\\ test}-p_{t-test}$\",fontsize=18)\n",
    "    elif error_type==\"rel\":\n",
    "        plt.ylabel(r\"$\\frac{p_{exact\\ test}-p_{t-test}}{p_{t-test}}$\",fontsize=20)\n",
    "        \n",
    "    plt.xlabel(\"Bin size\",fontsize=15)\n",
    "    \n",
    "    \n",
    "    plt.title(r\"$A=N(0,1),\\ B=N(\"+str(np.round(i*0.2,2))+\",1)$\",fontsize=22)\n",
    "    \n",
    "    if path:\n",
    "        fig.savefig(path+ str(i)+\".jpg\", bbox_inches='tight')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errorPlot(error, Bin, error_type=\"abs\", path=None):\n",
    "    y = np.asarray(error).mean(axis=1)\n",
    "    y_err = np.asarray(error).std(axis=1)\n",
    "    \n",
    "    \n",
    "    if error_type==\"abs\":\n",
    "        plt.ylabel(r\"$p_{exact\\ test}-p_{t-test}$\",fontsize=18)\n",
    "    elif error_type==\"rel\":\n",
    "        plt.ylabel(r\"$\\frac{p_{exact\\ test}-p_{t-test}}{p_{t-test}}$\",fontsize=25)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.errorbar(Bin,y,y_err)\n",
    "    \n",
    "    plt.xlabel(\"Bin size\",fontsize=15)\n",
    "    plt.ylabel(r\"$p_{exact\\ test}-p_{t-test}$\",fontsize=18)\n",
    "    plt.title(r\"$A=N(0,1),\\ B=N(\"+str(np.round(i*0.2,2))+\",1)$\",fontsize=20)\n",
    "    if path:\n",
    "        fig.savefig(path+ str(i)+\".jpg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boxplots: Absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (error, Bin) in enumerate(zip(all_experiment_dif, all_experiment_bins)):\n",
    "    boxPlot(error, Bin,\"figures/calibration/abs_box/box_abs_\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error-bar plot: Abolsute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (error, Bin) in enumerate(zip(all_experiment_dif, all_experiment_bins)):\n",
    "    errorPlot(error, Bin, \"figures/calibration/abs_error/error_abs_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boxplot: Relative error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (error, Bin) in enumerate(zip(all_experiment_rel_dif, all_experiment_bins)):\n",
    "    boxPlot(error, Bin, \"rel\", \"figures/calibration/rel_box/rel_box_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error-bar plot: Relative error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (error, Bin) in enumerate(zip(all_experiment_rel_dif, all_experiment_bins)):\n",
    "    errorPlot(error, Bin, \"rel\",\"figures/calibration/rel_error/rel_error_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python kth-cluster",
   "language": "python",
   "name": "kth-cluster"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
